## Review Generation

1. **Towards Automatic Generation of Product Reviews from Aspect-Sentiment Scores.**
*Hongyu Zang, Xiaojun Wan.*  INLG 2017. [paper](https://aclweb.org/anthology/W17-3526) 
@李军毅

1. **Learning to Generate Product Reviews from Attributes.**
*Li Dong, Shaohan Huang, Furu Wei, Mirella Lapata, Ming Zhou, Ke Xu.*  EACL 2017. [paper](http://www.aclweb.org/anthology/E17-1059) [code](https://drive.google.com/file/d/0B8yp1gOBCztycGlmbHM4emRhaTQ/view) [data](https://docs.google.com/forms/d/e/1FAIpQLSeCvpPDJ-evT1vRzRpdhRco0ayWUoLDOnhltgjbP_eklT3A9A/viewform)
@李军毅

1. **Learning to Generate Reviews and Discovering Sentiment.**
*Alec Radford, Rafal Jozefowicz, Ilya Sutskever.*  OpenAI 2016. [paper](http://arxiv.org/abs/1704.01444) [code](Learning to Generate Reviews and Discovering Sentiment)
@李军毅

1. **Context-aware Natural Language Generation with Recurrent Neural Networks.**
*Jian Tang, Yifan Yang, Sam Carton, Ming Zhang, Qiaozhu Mei.*  AAAI 2016. [paper](http://arxiv.org/abs/1611.09900)
@李军毅

## Text Summarization

1. **A Neural Attention Model for Abstractive Sentence Summarization.**
*Alexander M. Rush, Sumit Chopra, JasonWeston.*  EMNLP 2015. [paper](https://arxiv.org/pdf/1509.00685.pdf) 
@李军毅

1. **Abstractive sentence summarization with attentive recurrent neural networks.**
*Sumit Chopra, Michael Auli, Alexander M. Rush.*  NAACL 2016. [paper](http://www.aclweb.org/anthology/N16-1012) [code](https://github.com/toru34/rush_emnlp_2015)
@李军毅

1. **Incorporating Copying Mechanism in Sequence-to-Sequence Learning.**
*Jiatao Gu, Zhengdong Lu, Hang Li, Victor O.K. Li.*  ACL 2016. [paper](http://arxiv.org/abs/1603.06393) [code](https://github.com/MultiPath/CopyNet) [data](https://pan.baidu.com/s/1qYGB2Rq)
@李军毅

1. **Neural Summarization by Extracting Sentences and Words.**
*Jianpeng Cheng, Mirella Lapata.*  ACL 2016. [paper](http://www.aclweb.org/anthology/P16-1046) [code](https://github.com/MultiPath/CopyNet) [data](https://pan.baidu.com/s/1qYGB2Rq)
@李军毅

1. **Neural Network-Based Abstract Generation for Opinions and Arguments.**
*Lu Wang, Wang Ling.*  ACL 2016. [paper](https://arxiv.org/pdf/1606.02785.pdf) 
@李军毅

1. **Neural headline generation on abstract meaning representation.**
*Sho Takase, Jun Suzuki, Naoaki Okazaki, Tsutomu Hirao, Masaaki Nagata.*  EMNLP 2016. [paper](https://aclweb.org/anthology/D16-1112) 
@李军毅

1. **Abstractive text summarization using sequence-to-sequence RNNs and beyond.**
*Ramesh Nallapati, Bowen Zhou, Cicero dos Santos, Çaglar G ˘ ulçehre, Bing Xiang.*  CNLL 2016. [paper](http://cn.arxiv.org/pdf/1602.06023.pdf) 
@李军毅

1. **Language as a latent variable: Discrete generative models for sentence compression.**
*Yishu Miao, Phil Blunsom.*  EMNLP 2016. [paper](https://www.aclweb.org/anthology/D/D16/D16-1031.pdf) 
@李军毅

1. **Sequence level training with recurrent neural networks.**
*Marc’Aurelio Ranzato, Sumit Chopra, Michael Auli, Wojciech Zaremba.*  ICLR 2016. [paper](https://michaelauli.github.io/papers/iclr2016_mixer.pdf) 
@李军毅

1. **Deep Recurrent Generative Decoder for Abstractive Text Summarization.**
*Piji Li, Wai Lam, Lidong Bing, ZihaoWang.*  EMNLP 2017. [paper](http://aclweb.org/anthology/D17-1222) [code](https://github.com/toru34/li_emnlp_2017) 
@李军毅

1. **From Neural Sentence Summarization to Headline Generation: A Coarse-to-Fine Approach.**
*Jiwei Tan, Xiaojun Wan, Jianguo Xiao.*  IJCAI 2017. [paper](https://www.ijcai.org/proceedings/2017/0574.pdf) 
@李军毅

1. **Leveraging Contextual Sentence Relations for Extractive Summarization Using a Neural Attention Model.**
*Pengjie Ren, Zhumin Chen, Zhaochun Ren, FuruWei, Jun Ma, Maarten de Rijke.*  SIGIR 2017. [paper](https://staff.fnwi.uva.nl/m.derijke/wp-content/papercite-data/pdf/ren-leveraging-2017.pdf) 
@李军毅

1. **Diversity driven Attention Model for Query-based Abstractive Summarization.**
*Preksha Nema, Mitesh M. Khapra, Anirban Laha, Balaraman Ravindran.*  ACL 2017. [paper](https://arxiv.org/pdf/1704.08300.pdf) 
@李军毅

1. **Abstractive Document Summarization with a Graph-Based Attentional Neural Model.**
*Jiwei Tan, XiaojunWan, Jianguo Xiao.*  ACL 2017. [paper](http://www.aclweb.org/anthology/P17-1108) 
@李军毅

1. **SummaRuNNer: A recurrent neural network based sequence model for extractive summarization of documents.**
*Ramesh Nallapati, Feifei Zhai, Bowen Zhou.*  AAAI 2017. [paper](http://cn.arxiv.org/pdf/1611.04230.pdf) 
@李军毅

1. **Get To The Point: Summarization with Pointer-Generator Networks.**
*Abigail See, Peter J. Liu, Christopher D. Manning.*  ACL 2017. [paper](http://cn.arxiv.org/pdf/1704.04368.pdf) [code](https://github.com/abisee/pointer-generator) <br>
简介：把sequence-to-sequence模型应用于摘要生成时存在两个主要的问题：（1）难以准确复述原文的事实细节、无法处理原文中的未登录词(OOV)；（2）生成的摘要中存在重复的片段。针对这两个问题，本文提出融合了seq2seq模型和pointer network的pointer-generator network以及覆盖率机制(coverage mechanism)，在CNN/Daily Mail数据集上，相比于state-of-art，ROUGE分数提升了两个点。

1. **A Deep Reinforced Model for Abstractive Summarization.**
*Anonymous authors.*  ICLR 2018. [paper](https://arxiv.org/pdf/1705.04304.pdf) [code](https://github.com/MultiPath/CopyNet) [data](https://pan.baidu.com/s/1qYGB2Rq)
@李军毅

## Dialogue System

1. **A Persona-Based Neural Conversation Model.**
*Jiwei Li, Michel Galley, Chris Brockett.*  ACL 2016. [paper](http://arxiv.org/abs/1603.06155)
@李军毅

1. **Topic Augmented Neural Response Generation with a Joint Attention Mechanism.**
*Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang, Ming Zhou, Wei-Ying Ma.*  CoRR 2016. [paper](https://pdfs.semanticscholar.org/f5c1/a53daef462ce1120d64c13aa11ed88702547.pdf)
@李军毅

1. **Topic Aware Neural Response Generation.**
*Chen Xing, Wei Wu, Yu Wu, Jie Liu, Yalou Huang, Ming Zhou, Wei-Ying Ma.*  AAAI 2017. [paper](http://arxiv.org/abs/1606.08340)
@李军毅

1. **A Neural Conversational Model.**
*Oriol Vinyals, Quoc V. Le.*  ICML 2015. [paper](http://arxiv.org/abs/1506.05869)
@李军毅

1. **A Conditional Variational Framework for Dialog Generation.**
*Xiaoyu Shen, Hui Su, Yanran Li, Wenjie Li, Shuzi Niu, Yang Zhao, Akiko Aizawa, Guoping Long.*  ACL 2017. [paper](http://arxiv.org/abs/1705.00316)
@李军毅

1. **Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models.**
*Louis Shao, Stephan Gouws, Denny Britz, Anna Goldie, Brian Strope, Ray Kurzweil.*  EMNLP 2017. [paper](http://aclweb.org/anthology/D17-1235)
@李军毅

1. **Neural Response Generation via GAN with an Approximate Embedding Layer.**
*Zhen Xu, Bingquan Liu, Baoxun Wang, Chengjie Sun, Xiaolong Wang, Zhuoran Wang, Chao Qi.*  EMNLP 2017. [paper](http://aclweb.org/anthology/D17-1065)
@李军毅

1. **Neural Response Generation for Customer Service based on Personality Traits.**
*Jonathan Herzig, Michal Shmueli-Scheuer, Tommy Sandbank, David Konopnicki.*  INLG 2017. [paper](http://aclweb.org/anthology/W17-3541)
@李军毅

1. **Coherent Dialogue with Attention-based Language Models.**
*Hongyuan Mei, Mohit Bansal, Matthew R.Walter.*  AAAI 2017. [paper](https://arxiv.org/pdf/1611.06997.pdf)
@李军毅

1. **Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation.**
*Iulian Vlad Serban, Tim Klinger, Gerald Tesauro, Kartik Talamadupula, Bowen Zhou, Yoshua Bengio, Aaron Courville.*  AAAI 2017. [paper](http://cn.arxiv.org/pdf/1606.00776v1) [code](https://github.com/julianser/Ubuntu-Multiresolution-Tools)
@李军毅

1. **Mechanism-Aware Neural Machine for Dialogue Response Generation.**
*Ganbin Zhou, Ping Luo, Rongyu Cao, Fen Lin, Bo Chen, Qing He.*  AAAI 2017. [paper](https://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14471) [code](https://github.com/julianser/Ubuntu-Multiresolution-Tools)
@李军毅

1. **How to Make Context More Useful? An Empirical Study on Context-Aware Neural Conversational Models.**
*Zhiliang Tian, Rui Yan, Lili Mou, Yiping Song, Yansong Feng, Dongyan Zhao.*  ACL 2017. [paper](https://doi.org/10.18653/v1/P17-2036)
@李军毅

1. **Personalized Response Generation via Domain adaptation.**
*Min Yang, Zhou Zhao, Wei Zhao, Xiaojun Chen, Jia Zhu, Lianqiang Zhou, Zigang Cao.*  SIGIR 2017. [paper](http://delivery.acm.org/10.1145/3090000/3080706/p1021-yang.pdf?ip=218.106.182.55&id=3080706&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2E68C876273B0CA8EC%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=849390915&CFTOKEN=77149535&__acm__=1515488430_86da4807c41a1374799e732134445f61)
@李军毅


## Question Answering

1. **Neural Generative Question Answering.**
*Jun Yin, Xin Jiang, Zhengdong Lu, Lifeng Shang, Hang Li, Xiaoming Li.*  IJCAI 2016. [paper](https://arxiv.org/pdf/1512.01337.pdf) [data](https://github.com/jxfeb/Generative_QA)
@李军毅

1. **Generating Natural Answers by Incorporating Copying and Retrieving Mechanisms in Sequence-to-Sequence Learning.**
*Shizhu He, Cao Liu, Kang Liu, Jun Zhao.*  ACL 2017. [paper](http://www.nlpr.ia.ac.cn/cip/shizhuhe/articles/acl2017-coreqa.pdf)
@李军毅

1. **A Context-aware Attention Network for Interactive Question Answering.**
*Huayu Li, Martin Renqiang Min, Yong Ge, Asim Kadav.*  SIGKDD 2017. [paper](https://arxiv.org/pdf/1612.07411.pdf)
@李军毅

1. **Generating Query Suggestions to Support Task-Based Search.**
*Dar´ıo Garigliotti, Krisztian Balog.*  SIGIR 2017. [paper](https://arxiv.org/pdf/1708.08289.pdf)
@李军毅


## Machine Translation

1. **Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models.**
*Minh-Thang Luong, Christopher D.Manning.*  ACL 2016. [paper](http://www.aclweb.org/anthology/P16-1100) [code](https://github.com/lmthang/nmt.hybrid/tree/master/code) [data](https://github.com/lmthang/nmt.hybrid/tree/master/data)
@李军毅

1. **Tree-to-Sequence Attentional Neural Machine Translation.**
*Akiko Eriguchi, Kazuma Hashimoto, Yoshimasa Tsuruoka.*  ACL 2016. [paper](http://www.aclweb.org/anthology/P16-1078) [code](https://github.com/tempra28/tree2seq)
@李军毅

1. **Neural Machine Translation with Word Predictions.**
*Rongxiang Weng, Shujian Huang, Zaixiang Zheng, Xinyu Dai, Jiajun Chen.*  EMNLP 2017. [paper](http://aclweb.org/anthology/D17-1013) [code](https://github.com/tempra28/tree2seq)
@李军毅

1. **Improved Neural Machine Translation with Source Syntax.**
*Shuangzhi Wu, Ming Zhou, Dongdong Zhang.*  IJCAI 2017. [paper](https://www.ijcai.org/proceedings/2017/0584.pdf) 
@李军毅

1. **Joint Training for Pivot-based Neural Machine Translation.**
*Yong Cheng, Qian Yang, Yang Liu, Maosong Sun, Wei Xu.*  IJCAI 2017. [paper](http://www.larayang.com/others/pivotnmt.pdf) 
@李军毅

1. **ME-MD: An Effective Framework for Neural Machine Translation with Multiple Encoders and Decoders.**
*Jinchao Zhang, Qun Liu, Jie Zhou.*  IJCAI 2017. [paper](https://www.ijcai.org/proceedings/2017/0474.pdf) 
@李军毅

1. **Neural Machine Translation by Jointly Learning to Align and Translate.**
*Dzmitry Bahdanau, KyungHyun Cho, Yoshua Bengio.*  ICLR 2015. [paper](https://arxiv.org/pdf/1409.0473.pdf) [code](https://github.com/tensorflow/nmt)
@李军毅

1. **Modeling Coverage for Neural Machine Translation.**
*Zhaopeng Tu, Zhengdong Lu, Yang Liu, Xiaohua Liu, Hang Li.*  ACL 2016. [paper](http://www.aclweb.org/anthology/P16-1008) 
@李军毅

## Other

1. **Challenges in Data-to-Document Generation.**
*Sam Wiseman, Stuart M. Shieber, Alexander M. Rush.*  EMNLP 2017. [paper](http://arxiv.org/abs/1707.08052) [code](https://github.com/harvardnlp/data2text) [data](https://github.com/harvardnlp/boxscore-data)
@李军毅

1. **An Encoder-Decoder Framework Translating Natural Language to Database Queries.**
*Ruichu Cai, Boyan Xu, Xiaoyan Yang, Zhenjie Zhang, Zijian Li.*  AAAI 2018. [paper](https://arxiv.org/pdf/1711.06061.pdf)
@李军毅

1. **Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning.**
*Victor Zhong, Caiming Xiong, Richard Socher.*  Salesforce 2017. [paper](https://einstein.ai/static/images/layouts/research/seq2sql/seq2sql.pdf) [data](https://github.com/salesforce/WikiSQL)
@李军毅

1. **TopicRNN: A Recurrent Neural Network with Long-Range Semantic Dependency.**
*Adji B. Dieng, Chong Wang, Jianfeng Gao, John Paisley.*  ICLR 2017. [paper](https://arxiv.org/pdf/1611.01702.pdf) 
@李军毅

1. **Attention Is All You Need.**
*Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser.*  NIPS 2017. [paper](http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf) [code](https://github.com/jadore801120/attention-is-all-you-need-pytorch)
@李军毅

1. **Plan, Attend, Generate: Planning for Sequence-to-Sequence Models.**
*Francis Dutil, Caglar Gulcehre, Adam Trischler, Yoshua Bengio.*  NIPS 2017. [paper](http://papers.nips.cc/paper/7131-plan-attend-generate-planning-for-sequence-to-sequence-models.pdf)
@李军毅

1. **Adversarial Feature Matching for Text Generation.**
*Yizhe Zhang, Zhe Gan, Kai Fan, Zhi Chen, Ricardo Henao, Dinghan Shen, Lawrence Carin.*  ICML 2017. [paper](http://proceedings.mlr.press/v70/zhang17b/zhang17b.pdf)
@李军毅

1. **Joint Copying and Restricted Generation for Paraphrase.**
*Ziqiang Cao, Chuwei Luo, Wenjie Li, Sujian Li.*  AAAI 2017. [paper](http://www4.comp.polyu.edu.hk/~cszqcao/data/core.pdf) [code](https://github.com/kenchin110100/machine_learning/blob/master/sampleCopySeq2Seq.py)
@李军毅

1. **Data-Driven Broad-Coverage Grammars for Opinionated Natural Language Generation (ONLG).**
*Tomer Cagan, Stefan L. Frank, Reut Tsarfaty.*  ACL 2017. [paper](http://www.stefanfrank.info/pubs/acl2017-cr-4.pdf) 
@李军毅

1. **Convolutional Sequence to Sequence Learning.**
*Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, Yann N. Dauphin.*  ICML 2017. [paper](https://arxiv.org/pdf/1705.03122.pdf) [code](https://github.com/facebookresearch/fairseq)
@李军毅

1. **Learning to Ask: Neural Question Generation for Reading Comprehension.**
*Xinya Du, Junru Shao, Claire Cardie.*  ACL 2017. [paper](https://doi.org/10.18653/v1/P17-1123) [code](https://github.com/xinyadu/nqg)
@李军毅

1. **Affect-LM: A Neural Language Model for Customizable Affective Text Generation.**
*Sayan Ghosh, Mathieu Chollet, Eugene Laksana, Louis-Philippe Morency, Stefan Scherer.*  ACL 2017. [paper](https://doi.org/10.18653/v1/P17-1059)[code](https://github.com/xinyadu/nqg)
@李军毅
